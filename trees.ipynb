{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "#计算信息熵,，熵越高，混合的信息越多\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featureVec in dataSet:\n",
    "        currentLabel = featureVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] +=1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        #概率p(X)\n",
    "        prob = float(labelCounts[key] / numEntries)\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#划分数据集\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featureVec in dataSet:\n",
    "        #print(featureVec)\n",
    "        if featureVec[axis] == value:\n",
    "            #相当于reducedFeatVec = []\n",
    "            reducedFeatVec = featureVec[: axis]\n",
    "            reducedFeatVec.extend(featureVec[axis+1:])\n",
    "            retDataSet.append(featureVec[axis+1:])\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creatDataSet():\n",
    "    dataSet = [\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "    ]\n",
    "    labels = ['no surrfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels= creatDataSet()\n",
    "splitDataSet(data, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    #print(\"base：%f\" % baseEntropy)\n",
    "    bestInfoGain = 0.0 \n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featureList = [example[i] for example in dataSet]\n",
    "        #print(featureList)\n",
    "        uniqueVals = set(featureList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "            #print(\"newEntropy: %s\" % newEntropy)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        #print(\"infoGain: %s, bestInfoGain: %s\" % (infoGain, bestInfoGain))\n",
    "        if infoGain > bestInfoGain:\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base：0.811278\n",
      "[1, 1, 0, 0]\n",
      "newEntropy: 0.0\n",
      "newEntropy: 0.5\n",
      "infoGain: 0.31127812445913283, bestInfoGain: 0.0\n",
      "[1, 0, 1, 1]\n",
      "newEntropy: 0.0\n",
      "newEntropy: 0.6887218755408672\n",
      "infoGain: 0.12255624891826566, bestInfoGain: 0.31127812445913283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def majortyCount(classList):\n",
    "    classCount ={}\n",
    "    for vote in classList:\n",
    "        if vote in classList.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    print(\"classList %s\" % classList)\n",
    "    print(\"dataSet %s\" % dataSet)\n",
    "    #列表第一个类别的个数与列表元素个数是否一致， 即只剩下一个类别时结束递归\n",
    "    if classList.count(classList[0])  == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majortyCount(classList)\n",
    "    bestFeat = chooseBestFeatureSplit(dataSet)\n",
    "    print(bestFeat)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in  dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classList ['yes', 'no', 'no', 'no']\n",
      "dataSet [[1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "0\n",
      "classList ['no', 'no']\n",
      "dataSet [[1, 'no'], [1, 'no']]\n",
      "classList ['yes', 'no']\n",
      "dataSet [[1, 'yes'], [0, 'no']]\n",
      "0\n",
      "classList ['no']\n",
      "dataSet [['no']]\n",
      "classList ['yes']\n",
      "dataSet [['yes']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no surrfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet, labels = creatDataSet()\n",
    "myTree = createTree(dataSet, labels)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree, featLabels, testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    #print(featLabels)\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if  type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['no surrfacing'])\n",
      "dict_keys(['flippers'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet, labels = creatDataSet()\n",
    "classify(myTree, labels, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存决策树(字典对象保存)\n",
    "import pickle\n",
    "def storeTree(inputTree, filename):\n",
    "    fw = open(filename,'w')\n",
    "    pickle.dump(inputTree, fw)\n",
    "    fw.close()\n",
    "\n",
    "def getTree(filename):\n",
    "    fr = open(filename,'r')\n",
    "    return pickle.load(fr)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
